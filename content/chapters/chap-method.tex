\chapter{Flexible Interactive Retrieval System and Best Practices for Visual Retrieval}
\label{chap-first}
\begin{ChapAbstract}
In this chapter, we describe our retrieval system called FIRST in details. We provide an overview of the system in Section \ref{sec:FIRST_overview} and discuss our system design in Section \ref{sec:first_system_design}. Section \ref{sec:first_front_end_design} concerns the user interfaces and interactions, while Section \ref{sec:first_back_end_design} focuses on the AI-related components that assist the user during the retrieval process. Finally, in the last three sections, we introduce more details about the Lifelog Search Challenge 2022 and Visual Browser Showdown 2022, the evaluation metrics used in these challenges and the result of our interactive retrieval system on each challenge.
\end{ChapAbstract}
\input{content/chapters/retrieval_application_tex/first}

\chapter{Referring Expression Segmentation}
\label{chap-refer-seg}
\begin{ChapAbstract}
In this chapter, we present our proposed method for referring expression segmentation called VLFormer. We first provide an overview of our method in Section \ref{sec:rvos_overview}. In Section \ref{sec:rvos_architecture}, we then describe our architecture in details. Our training strategy is mentioned in Section \ref{sec:rvos_training_strategy}. Then, we discuss our extended version to the video that consists of a selection strategy to choose the final object and the post-processing strategy by Semi-VOS methods for better refinement in Section \ref{sec:rvos_inference}. Section \ref{sec:rvos_ytvos} and \ref{sec:ris_dataset} present datasets we conduct the experiments and the performance of our method on those datasets. Finally, we analyse the qualitative results of our referring expression segmentation framework in Section \ref{sec:rvos_qualitative_analysis}.


\end{ChapAbstract}

\input{chapters/referring_segmentation_tex/overview}
\input{chapters/referring_segmentation_tex/architecture}
\input{chapters/referring_segmentation_tex/training_strategy}
\input{chapters/referring_segmentation_tex/inference}
\input{chapters/referring_segmentation_tex/video}
\input{chapters/referring_segmentation_tex/exp_refer}
\input{chapters/referring_segmentation_tex/retrieval}