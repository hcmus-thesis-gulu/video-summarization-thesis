\vspace{-2mm}
\section{Motivation}
\label{sec:motivation}
\vspace{-2mm}
Information retrieval is a field that predates the popular usage of computers. With more and more data being generated by humans, a better method to search than a linear scan is essential. Observing the current advances in artificial intelligence and in Computer Vision and Natural Language Processing specifically, we seek to apply those techniques to create a smart interactive retrieval system supporting the practical need of searching in a collection of visual data.

\vspace{-2mm}
Though we have popular commercialized search engines that have billions of users, their primary focus is on the web, which is primarily text-based, making it easier to index billions of pages. A text-to-image search engine with similar popularity is not readily available yet. Google Images, for example, relies on the text presented on the same page as images to understand them. We want to build a system that can analyze images based on their content and incorporate structured and unstructured accompanying metadata, which exists with camera-generated images and online videos.

However, there are a few challenges associated with building such a system.
\begin{itemize}
\vspace{-2mm}
    \item First, the colossal size of the data to be processed is an immense challenge on its own. We are not aiming at mobile galleries; we are talking about wearable cameras that can generate videos at 30 frames per second (FPS) or surveillance cameras that also generate videos at dozens of FPS. Even with 2 FPS, a reasonable rate for lifelogging, such cameras already produce 2880 images a day, or 86400 images a month. Compression techniques can help reduce the storage, but if left unattended, the data can become a waste and face disposal.
\vspace{-2mm}
    \item Second, developers are proficient with their own system but have difficulty bringing the same ease of use to other users. There can be various reasons for this. Often, in order to boost performance, developers install features that make it different from existing systems; however, this also creates surprises for the user, making them unable to utilize the system fully.
\vspace{-2mm}    
    \item Third, while enjoying more flexibility than traditional databases, AI-based systems can suffer from a lack of explainability. When only items are returned, there is little indication of why they are yielded. This can be a problem when relevance can not be easily verified with bare eyes, for example, when the images come from a different domain (medical, poor lighting, etc.). It should be noted that ordinary databases provide no solution to this problem either, however, AI-assisted systems can be modified to include a certain indicator, for example, localization of concepts in the query itself.
\end{itemize}

\vspace{-2mm}
Existing systems suffer from one or all of these problems. We want to apply artificial intelligence to create a system that can tackle all of these problems at once, i.e., it should be scalable, the user should be able to use it without needing an AI background, and it has to have explainability.

% The Natural Language-Based Vehicle Retrieval track is really tough since it requires applying knowledge across CV and NL Processing. Despite this, it promises an important and practical problem. There are three reasons supporting this statement.

% Firstly, search is a must-have function in any large system. It is not the issue that data is so colossal and people can never manually remember all of its features, but it is the duty of intelligent systems when they must have the ability to filter robustly, sort quickly, and give the best possible results to satisfy the users' expectations. There are two aspects users are concerned with when making a search: (i) the form of input, (ii) the data processed and returned for them. With regard to input, the most basic and convenient way to retrieve is by giving the system a textual query. Meanwhile, in transportation, they want to get information about traffic events, which were recorded as videos, the most. Also, as mentioned in section [x] , people pay greater attention to the vehicle than any object as it is the focal point of all activities. Therefore, building the model capable of identifying the best-matching video with descriptions about a vehicle’s information like motion attributes, appearance features, relations to other in-traffic vehicles, and other relevant events is fundamental but crucial for the ITS.

% Secondly, there has not been any accurate baselined method for this track. Although the Video Retrieval problem has recently been on an upward trend, it lacks development in particular objects. In very general domains, people still have been confronted by a semantic gap between two modalities. This track concentrates on a specific domain - vehicle, so making the gap become more challenging than ever, when the model needs to not only grasp the textual input but also to be able to discriminate among so many similar vehicles and their events to process the video contents. It is extremely necessary to propose constructive-developmental approaches for this problem.

% Finally, it is about the impact. We hope that the model in particular, and the NL-based VR track in general, can get greater attention to advanced progress: (i) make the model deeply understand more insights from the NL inputs so as to narrow the semantic gap to videos, (ii) make use of other data types such as GPS, velocity, traffic volume, etc. from various sensor sources to perform better outcomes, as a premiere for future deployments in law enforcement, or other search-oriented modules in traffic administration. Furthermore, the objective of researching cutting-edge models is not only to put it into practice but also to expand the retrieval’s influence in divergent non-human areas. It is an expectation that these models would serve as a starting point for retrieval problems targeting objects like the plant, animal, leaf, insect, etc. in Agriculture, the organ, cell in Medical, or the food, beverage in F\&B service, and so on.

% As a result, the NL-based VR problem has a genuine chance of being widely researched and integrated into ITSs.
% It can be treated as cross-modal retrieval of visual data using natural language descriptions. The typical approach for such problems is to embed visual and textual information into the same semantic space for similarity measurement. 
% Handling the problem this way requires a large training dataset enough for the model to learn various types of descriptions.
% In the scope of practical vehicle-oriented retrieval, the queries mainly concentrate on describing the target vehicles while the video provides both targets’ attributes and trajectories. 
% Another restriction of practical problems for deep modeling is that the available learning dataset is usually small due to labor-intensive and uncertain real-life conditions. 

% Therefore, to efficiently handle the ITS city-scale retrieval problem, current state-of-the-art approaches explore different ways to embed both the global context of the entire video and local context containing target vehicle features for a better representation. Furthermore, to tackle the shortage of valuable datasets, they ensemble features from multiple backbones and extract richer features to achieve potential results. 
% These methods provide end-to-end processes but lack explainability and cost extensive computational power due to the usage of many deep learning models, which may lead to difficulty for real-life deployment.
% Other approaches focus on descriptive querying cues to perform searching. They propose hierarchical systems to filter different attributes of the target vehicle such as color, vehicle type, moving directions, etc. Tackling the problem this way is more explainable and reduces the hardware computational stress, but it highly depends on the quality of training data. 

% These disadvantages motivate us to build a system with less computing cost, more explainability, and high possibility of real-life deployment.
% We propose a multi-module vehicle-based retrieval system that does not depend too much on deep models but also concentrates on different attributes of the mentioned vehicle and produces competitive results.
% We inherit the success of representation learning-based approaches to implement a retrieval module that returns a list of candidate videos for each query. Then, we adopt different modules; each is responsible for capturing an essential attribute of the target vehicle to refine the candidate result. Experiments show that our proposed approach achieves state-of-the-art results with only a single embedding model.

