% \begin{table}[H]
%         \centering
%         \begin{tabular}{cc}
%             \hline
%             \textbf{Queries} & \textbf{IoU} \\ \hline
%             1                & 71.6             \\
%             5                & 72.52        \\
%             10               & 72.3         \\
%             20               & 71.9             \\ \hline
%         \end{tabular}
%     % \begin{minipage}{.4\textwidth}
%     %     \centering
%     %     \begin{tabular}{cc}
%     %         \hline
%     %         \textbf{Queries} & \textbf{IoU} \\ \hline
%     %         1                & 71.6             \\
%     %         5                & 72.52        \\
%     %         10               & 72.3         \\
%     %         20               & 71.9             \\ \hline
%     %     \end{tabular}
%     % \end{minipage}
%     % \begin{minipage}{.4\textwidth}
%     %   \centering
%     %     \begin{tabular}{cc}
%     %         \hline
%     %         \textbf{Queries} & \textbf{IoU} \\ \hline
%     %         1                &              \\
%     %         5                & 72.52        \\
%     %         10               &              \\
%     %         20               &              \\ \hline
%     %     \end{tabular}
%     % \end{minipage}
    
%     \caption{
%         % 
%         Ablation study on RefCOCO set. All the models are using ResNet-101 as visual backbone.
%         % 
%         } % \caption
%         \label{tab:refyoutube2022}
%   \end{table}
  

\begin{table*}[h]
\centering
\begin{tabular}{c|c|c|c|c|c|c}
\toprule
\multicolumn{1}{c|}{} & Prec@0.5 & Prec@0.6 & Prec@0.7 & Prec@0.8 & Prec@0.9 & IoU \\
\midrule
\multicolumn{7}{l}{\textbf{(a)} Number of Visual-Language Transformer layers $(L)$}                                                                                                                                                                                                             \\ \midrule
0                          & 79.67             & 76.60             & 71.77             & 61.89             & 33.36             & 70.21   \\
1                          & 83.27             & 80.56             & 76.43             & 66.81             & 37.78             & 73.45   \\
2                        & \textbf{83.82}             & \textbf{81.18}             & \textbf{76.84}             & \textbf{67.48}             & \textbf{37.89}             & \textbf{73.92}   \\ \midrule
\multicolumn{7}{l}{\textbf{(b)} Text Encoder model}                                                                                                                                                                                                     \\ \midrule
CLIP                      & \textbf{83.82}             & \textbf{81.18}             & \textbf{76.84}             & \textbf{67.48}             & \textbf{37.89}             & \textbf{73.92}   \\
BERT                       & 79.85             & 77.54             & 73.80             & 65.23             & 36.62             & 70.73   \\ \midrule
\multicolumn{7}{l}{\textbf{(c)}Language Guidance Module (LGM)}                                                                                                                                                                                          \\ \midrule
With LGM                  & \textbf{83.82}             & \textbf{81.18}             & \textbf{76.84}             & \textbf{67.48}             & \textbf{37.89}             & \textbf{73.92}   \\
W/o LGM                    & 73.93             & 71.26             & 67.42             & 58.81             & 33.14             & 65.19   \\ \midrule
\multicolumn{7}{l}{\textbf{(d)} Number of object queries $(N)$}                                                                                                                                                                                                             \\ \midrule
1                          & 82.47             & 78.85             & 73.34             & 62.90              & 33.31             & 72.59   \\
3                          & 83.19             & 80.31             & 75.60             & 65.97              & 36.41             & 73.18   \\
5                          & \textbf{83.82}             & \textbf{81.18}             & \textbf{76.84}             & \textbf{67.48}             & \textbf{37.89}             & \textbf{73.92}   \\
8                          & 82.12             & 79.44             & 75.03             & 65.89              & 36.28             & 72.47   \\
10                         & 82.77             & 80.29             & 75.98             & 66.52             & 36.27             & 73.04
 \\ \bottomrule
\end{tabular}
\caption{\textbf{Ablation Study on RefCOCO.} The experiments are based on ResNet-50 visual backbone and conducted on the validation split of RefCOCO. W/o LGM indicates that LGM is not used in the Cross-modal Pixel Decoder}
\label{tab:ablation}
\end{table*}